{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62638171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "tensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "numpy = lambda x : x.detach().cpu().numpy()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def load_nii_file(fname, threshold=.5):\n",
    "    mask = sitk.GetArrayFromImage(sitk.ReadImage(fname))\n",
    "    verts, faces, normals, values = skimage.measure.marching_cubes_lewiner(mask, threshold)\n",
    "    return to_measure(verts, faces)\n",
    "def to_measure(points, triangles):\n",
    "    A, B, C = points[triangles[:, 0]], points[triangles[:, 1]], points[triangles[:, 2]]\n",
    "    X = (A + B + C) / 3 \n",
    "    S = np.sqrt(np.sum(np.cross(B - A, C - A) ** 2, 1)) / 2 \n",
    "    return tensor(S / np.sum(S)), tensor(X)\n",
    "if __name__ == \"__main__\":\n",
    "    points = load_nii_file(\"BronchialTree.nii\") \n",
    "    print(points[0].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c73efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = points[0].numpy()\n",
    "coordinates = points[1].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f92e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(coordinates[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d94e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyElement,  PlyData\n",
    "def write_ply(points, filename, text=True):\n",
    "    points = [(points[i,0], points[i,1], points[i,2]) for i in range(points.shape[0])]\n",
    "    vertex = np.array(points, dtype=[('x', 'f4'), ('y', 'f4'),('z', 'f4')])\n",
    "    el = PlyElement.describe(vertex, 'vertex', comments=['vertices'])\n",
    "    PlyData([el], text=text).write(filename)\n",
    "write_ply(coordinates, \"test.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a48ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "def display_cloud(ax, measure, color):\n",
    "    w_i, x_i = numpy(measure[0]), numpy(measure[1])\n",
    "    ax.view_init(elev=110, azim=-90)\n",
    "    weights = w_i / w_i.sum()\n",
    "    ax.scatter(x_i[:, 0], x_i[:, 1], x_i[:, 2], s=25 * 500 * weights, c=color)\n",
    "    ax.axes.set_xlim3d(left=-200, right=200)\n",
    "    ax.axes.set_ylim3d(bottom=-200, top=200)\n",
    "    ax.axes.set_zlim3d(bottom=-200, top=200)\n",
    "ax = plt.subplot(111, projection='3d')\n",
    "display_cloud(ax, points, \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(coordinates)\n",
    "o3d.io.write_point_cloud(\"./data.ply\", pcd)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "tf.random.set_seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ec1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = tf.keras.utils.get_file(\n",
    "    \"modelnet.zip\",\n",
    "    \"http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "DATA_DIR = os.path.join(os.path.dirname(DATA_DIR), \"ModelNet10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2a6a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mesh = trimesh.load(os.path.join(DATA_DIR, \"chair/train/chair_0001.off\"))\n",
    "mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cbd293",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = mesh.sample(2048)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.scatter(points[:, 0], points[:, 1], points[:, 2])\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19ae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0399179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(num_points=2048):\n",
    "\n",
    "    train_points = []\n",
    "    train_labels = []\n",
    "    test_points = []\n",
    "    test_labels = []\n",
    "    class_map = {}\n",
    "    folders = glob.glob(os.path.join(DATA_DIR, \"[!README]*\"))\n",
    "\n",
    "    for i, folder in enumerate(folders):\n",
    "        print(\"processing class: {}\".format(os.path.basename(folder)))\n",
    "        class_map[i] = folder.split(\"/\")[-1]\n",
    "        train_files = glob.glob(os.path.join(folder, \"train/*\"))\n",
    "        test_files = glob.glob(os.path.join(folder, \"test/*\"))\n",
    "\n",
    "        for f in train_files:\n",
    "            train_points.append(trimesh.load(f).sample(num_points))\n",
    "            train_labels.append(i)\n",
    "\n",
    "        for f in test_files:\n",
    "            test_points.append(trimesh.load(f).sample(num_points))\n",
    "            test_labels.append(i)\n",
    "\n",
    "    return (\n",
    "        np.array(train_points),\n",
    "        np.array(test_points),\n",
    "        np.array(train_labels),\n",
    "        np.array(test_labels),\n",
    "        class_map,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e35587",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(test_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c886123",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS = 2048\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_points, test_points, train_labels, test_labels, CLASS_MAP = parse_dataset(\n",
    "    NUM_POINTS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4954c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_train = []\n",
    "point_test = []\n",
    "array = []\n",
    "print(len(train_points))\n",
    "for i in range(len(train_points)):\n",
    "    array.append([0,0,0])\n",
    "point_test = np.array(array)\n",
    "point_test = np.expand_dims(point_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fc5472",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(point_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a292b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(points, label):\n",
    "    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n",
    "    points = tf.random.shuffle(points)\n",
    "    return points, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aad455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e036f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc5e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnet(inputs, num_features):\n",
    "\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    reg = OrthogonalRegularizer(num_features)\n",
    "\n",
    "    x = conv_bn(inputs, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 512)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = dense_bn(x, 128)\n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ff104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "inputs = keras.Input(shape=(NUM_POINTS, 3))\n",
    "x = tnet(inputs, 3)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = tnet(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 512)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = dense_bn(x, 256)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = dense_bn(x, 128)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "a_input = keras.Input(shape=(1, 3))\n",
    "a = layers.GlobalMaxPooling1D()(a_input)\n",
    "a = dense_bn(a, 128)\n",
    "\n",
    "print(np.shape(a))\n",
    "print(np.shape(x))\n",
    "mergedOutput = Concatenate()([a, x])\n",
    "out = Dense(128, activation='relu')(mergedOutput)\n",
    "out = Dropout(0.8)(out)\n",
    "out = Dense(32, activation='sigmoid')(out)\n",
    "out = Dense(NUM_CLASSES, activation='softmax')(out)\n",
    "\n",
    "\n",
    "\n",
    "model = keras.Model(inputs=[inputs, a_input], outputs=out, name=\"pointnet\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f3fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(model.output_shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b45fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(x = [train_points, point_test], y= [train_labels], epochs=20, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8057c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = test_dataset.take(1)\n",
    "\n",
    "points, labels = list(data)[0]\n",
    "points = points[:8, ...]\n",
    "labels = labels[:8, ...]\n",
    "\n",
    "preds = model.predict(points)\n",
    "preds = tf.math.argmax(preds, -1)\n",
    "\n",
    "points = points.numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "for i in range(8):\n",
    "    ax = fig.add_subplot(2, 4, i + 1, projection=\"3d\")\n",
    "    ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2])\n",
    "    ax.set_title(\n",
    "        \"pred: {:}, label: {:}\".format(\n",
    "            CLASS_MAP[preds[i].numpy()], CLASS_MAP[labels.numpy()[i]]\n",
    "        )\n",
    "    )\n",
    "    print(\"prediction: \" + CLASS_MAP[preds[i].numpy()])\n",
    "    print(\"label: \" + CLASS_MAP[labels.numpy()[i]])\n",
    "    ax.set_axis_off()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd90c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(coordinates)\n",
    "o3d.io.write_point_cloud(\"./data.ply\", pcd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227917de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(\"data.ply\")\n",
    "print(pcd)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b1958e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b47ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh2 = trimesh.load(\"data.ply\")\n",
    "mesh2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bedf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf42e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "downpcd = pcd.voxel_down_sample(voxel_size=7.409)\n",
    "print(downpcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3caedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([downpcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e344ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "down_points = np.asarray(downpcd.points)\n",
    "down_points = np.expand_dims(down_points, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ebfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(down_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a4e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_points[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6187c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(down_points)\n",
    "preds = tf.math.argmax(preds, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa87ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(preds[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dfd57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CLASS_MAP[preds[0].numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c392394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d201417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
