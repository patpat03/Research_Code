{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3055b981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  35.8555   93.6012 1194.74  ]\n",
      " [ -16.7894   95.8828 1194.48  ]\n",
      " [  35.8512   93.6082 1194.78  ]\n",
      " ...\n",
      " [  14.0563  161.424  1428.38  ]\n",
      " [  14.5352  161.401  1428.37  ]\n",
      " [  15.1151  161.318  1428.26  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyvista as pv\n",
    "mesh = pv.read(\"BronchialTree.obj\")\n",
    "print(mesh.points)\n",
    "point = [0.1, 0.2, 0.3]\n",
    "index = mesh.find_closest_cell(point)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94a6c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lines = []\n",
    "directions = []\n",
    "with open('rename5.txt') as f:\n",
    "    lines = f.read().splitlines()\n",
    "for i in range(len(lines)):\n",
    "    lines[i] = [float(a) for a in lines[i].split()]\n",
    "positives = []\n",
    "for l in lines:\n",
    "    positives.append(l[0:3])\n",
    "    directions.append(l[3:])\n",
    "d = directions\n",
    "directions = [[x[0] * 100, x[1] * 100, x[2] * 100] for x in directions]\n",
    "directions = np.array(directions)\n",
    "positives = np.array(positives)\n",
    "directions = np.add(positives, directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19848d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(positives)\n",
    "pcd.paint_uniform_color([1, 0.706, 0])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc0dd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointCloud with 475 points."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd.voxel_down_sample(voxel_size=4.65175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d114181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "cloud = np.stack(np.array(mesh.points))\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(cloud)\n",
    "downpcd = pcd.voxel_down_sample(voxel_size=4.65175)\n",
    "p_cloud = np.asarray(downpcd.points)\n",
    "data_cloud = []\n",
    "labels = []\n",
    "for i in range(len(positives)):\n",
    "    data_cloud.append(p_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "765aa880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(data_cloud[0])\n",
    "pcd.paint_uniform_color([1, 0.706, 0])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4504ed33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24497866855277678"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "angle_between([0,1, 19199], [1, 0, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d7fea3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pyvista\n",
    "points = []\n",
    "pos = []\n",
    "neg = []\n",
    "counter = 0\n",
    "for i in range(2000):\n",
    "    index = mesh.find_closest_cell(positives[i])\n",
    "    normal = mesh.cell_normals[index]\n",
    "    normal = [-normal[0], -normal[1], -normal[2]]\n",
    "    normal = np.add(mesh.cell_centers().points[index], normal)\n",
    "    d[i] = [-d[i][0], -d[i][1], -d[i][2]]\n",
    "    if angle_between(normal, d[i]) < math.pi/4:\n",
    "        pos.append(mesh.cell_centers().points[index])\n",
    "    else:\n",
    "        neg.append(mesh.cell_centers().points[index])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55e47ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def closest_point(target, points):\n",
    "    c_point = []\n",
    "    d = 100000\n",
    "    for i in points:\n",
    "        if math.dist(target, i) < d:\n",
    "            d = math.dist(target, i)\n",
    "            c_point = i\n",
    "    return c_point\n",
    "new_neg = []\n",
    "for j in neg:\n",
    "    if math.dist(closest_point(j, pos), j) > 2:\n",
    "        new_neg.append(j)\n",
    "len(new_neg)\n",
    "neg = new_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec34c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pos)\n",
    "pcd.paint_uniform_color([0, 0.706, 0])\n",
    "\n",
    "pcd2 = o3d.geometry.PointCloud()\n",
    "pcd2.points = o3d.utility.Vector3dVector(neg)\n",
    "pcd2.paint_uniform_color([0.5, 0, 0])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd, pcd2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99a8e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "pos = np.stack(pos)\n",
    "neg = np.stack(neg)\n",
    "hash = {}\n",
    "array = []\n",
    "for i in pos:\n",
    "    array.append([i, 1])\n",
    "for i in neg:\n",
    "    array.append([i, 0])\n",
    "random.shuffle(array)\n",
    "points = []\n",
    "labels = []\n",
    "for i in array:\n",
    "    points.append(i[0])\n",
    "    labels.append(i[1])\n",
    "points = np.stack(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5613bf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pos)\n",
    "pcd.paint_uniform_color([1, 0.706, 0])\n",
    "\n",
    "pcd2 = o3d.geometry.PointCloud()\n",
    "pcd2.points = o3d.utility.Vector3dVector(neg)\n",
    "pcd2.paint_uniform_color([0.5, 0, 0])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd, pcd2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7a292b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def augment(points):\n",
    "    # jitter points\n",
    "    # shuffle points\n",
    "    points = tf.random.shuffle(points)\n",
    "    return points\n",
    "for i in range(len(data_cloud)):\n",
    "    data_cloud[i] = augment(data_cloud[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3aad455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters,kernel_initializer='ones',\n",
    "    kernel_regularizer=tf.keras.regularizers.L1(0.1),\n",
    "    activity_regularizer=tf.keras.regularizers.L2(0.1))(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "def dense_bn2(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e036f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbc5e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnet(inputs, num_features):\n",
    "\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    reg = OrthogonalRegularizer(num_features)\n",
    "\n",
    "    x = conv_bn(inputs, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 512)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = dense_bn(x, 128)\n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "995ff104",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pointnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 2048, 3)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 2048, 32)     128         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 2048, 32)    128         ['conv1d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 2048, 32)     0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 2048, 64)     2112        ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 2048, 64)    256         ['conv1d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 2048, 64)     0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 2048, 512)    33280       ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 2048, 512)   2048        ['conv1d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 2048, 512)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " global_max_pooling1d_8 (Global  (None, 512)         0           ['activation_42[0][0]']          \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 256)          131328      ['global_max_pooling1d_8[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 256)         1024        ['dense_24[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 256)          0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 128)          32896       ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 128)         512         ['dense_25[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 128)          0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 9)            1161        ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 3, 3)         0           ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " dot_4 (Dot)                    (None, 2048, 3)      0           ['input_5[0][0]',                \n",
      "                                                                  'reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 2048, 32)     128         ['dot_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 2048, 32)    128         ['conv1d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 2048, 32)     0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 2048, 32)     1056        ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 2048, 32)    128         ['conv1d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 2048, 32)     0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 2048, 32)     1056        ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 2048, 32)    128         ['conv1d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 2048, 32)     0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 2048, 64)     2112        ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 2048, 64)    256         ['conv1d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 2048, 64)     0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 2048, 512)    33280       ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 2048, 512)   2048        ['conv1d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_49 (Activation)     (None, 2048, 512)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " global_max_pooling1d_9 (Global  (None, 512)         0           ['activation_49[0][0]']          \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 256)          131328      ['global_max_pooling1d_9[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 256)         1024        ['dense_27[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 256)          0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 128)          32896       ['activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 128)         512         ['dense_28[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 128)          0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 1024)         132096      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 32, 32)       0           ['dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " dot_5 (Dot)                    (None, 2048, 32)     0           ['activation_46[0][0]',          \n",
      "                                                                  'reshape_5[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 2048, 32)     1056        ['dot_5[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 2048, 32)    128         ['conv1d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 2048, 32)     0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 2048, 64)     2112        ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 2048, 64)    256         ['conv1d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 2048, 64)     0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 2048, 512)    33280       ['activation_53[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 2048, 512)   2048        ['conv1d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 2048, 512)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 1, 3)]       0           []                               \n",
      "                                                                                                  \n",
      " global_max_pooling1d_10 (Globa  (None, 512)         0           ['activation_54[0][0]']          \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " global_max_pooling1d_11 (Globa  (None, 3)           0           ['input_6[0][0]']                \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 256)          131328      ['global_max_pooling1d_10[0][0]']\n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 256)          1024        ['global_max_pooling1d_11[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 256)         1024        ['dense_30[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 256)         1024        ['dense_32[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 256)          0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 256)          0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 256)          0           ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 128)          32896       ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 1)            257         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 128)         512         ['dense_33[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 1)           4           ['dense_31[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 128)          0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_56 (Activation)     (None, 1)            0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 129)          0           ['activation_58[0][0]',          \n",
      "                                                                  'activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 128)          16640       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 128)         512         ['dense_34[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 128)          0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 2)            258         ['activation_59[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 767,408\n",
      "Trainable params: 760,558\n",
      "Non-trainable params: 6,850\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import layers\n",
    "inputs = keras.Input(shape=(2048, 3))\n",
    "x = tnet(inputs, 3)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = tnet(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 512)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = dense_bn(x, 256)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = dense_bn(x, 1)\n",
    "\n",
    "a_input = keras.Input(shape=(1, 3))\n",
    "a = layers.GlobalMaxPooling1D()(a_input)\n",
    "a = dense_bn2(a, 256)\n",
    "a = dense_bn2(a, 128)\n",
    "mergedOutput = Concatenate()([a,x])\n",
    "out = dense_bn2(mergedOutput,128)\n",
    "out = Dense(2, activation='softmax')(out)\n",
    "\n",
    "\n",
    "\n",
    "model = keras.Model(inputs=[inputs, a_input], outputs=out, name=\"pointnet\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53b45fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.expand_dims(points, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebf222d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "labels = numpy.asarray(labels)\n",
    "data_cloud = numpy.asarray(data_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1fd04c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0 1 0 ... 1 0 0] | test: [1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1\n",
      " 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1\n",
      " 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1\n",
      " 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1\n",
      " 1 1 1 1 1 0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 0 0 1 1 1 1 0 0\n",
      " 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0\n",
      " 1 0 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1\n",
      " 0 0 0 1 1 0 0 1 1 1 0]\n",
      "Epoch 1/5\n",
      "43/43 [==============================] - 140s 3s/step - loss: 16289379.0000 - sparse_categorical_accuracy: 0.8378\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 136s 3s/step - loss: 500850.5938 - sparse_categorical_accuracy: 0.8705\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 173s 4s/step - loss: 95002.7266 - sparse_categorical_accuracy: 0.8822\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 195s 5s/step - loss: 47687.2422 - sparse_categorical_accuracy: 0.8713\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 197s 5s/step - loss: 37803.9961 - sparse_categorical_accuracy: 0.8895\n",
      "test case:\n",
      "0.8430232558139534\n",
      "Train: [1 0 0 ... 1 0 0] | test: [0 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 1 0 1\n",
      " 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 0 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0\n",
      " 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 1 1\n",
      " 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0\n",
      " 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1\n",
      " 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0\n",
      " 1 1 1 0 1 1 1 0 1 1 0]\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10528/453324497.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mpoints_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata_cloud_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoints_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test case:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_cloud_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoints_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    978\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 980\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    981\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "k_fold = KFold(n_splits=5)\n",
    "for train_indices, test_indices in k_fold.split(labels):\n",
    "    model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "    print('Train: %s | test: %s' % (labels[train_indices], labels[test_indices]))\n",
    "    labels_train = labels[train_indices]\n",
    "    data_cloud_train = data_cloud[train_indices]\n",
    "    points_train = points[train_indices]\n",
    "    \n",
    "    labels_test = labels[test_indices]\n",
    "    data_cloud_test = data_cloud[test_indices]\n",
    "    points_test = points[test_indices]\n",
    "    \n",
    "    labels_test = tf.convert_to_tensor(labels_test)\n",
    "    data_cloud_test= tf.convert_to_tensor(data_cloud_test)\n",
    "    points_test = tf.convert_to_tensor(points_test)\n",
    "    \n",
    "    model.fit(x = [data_cloud_train, points_train], y= [labels_train], epochs=5)\n",
    "    print(\"test case:\")\n",
    "    preds = model.predict([data_cloud_test, points_test])\n",
    "    predictions = tf.math.argmax(preds, -1)\n",
    "    wrong = 0\n",
    "    labels_test = labels_test.numpy()\n",
    "    predictions = predictions.numpy()\n",
    "    for i in range(len(predictions)):\n",
    "        if(predictions[i] != labels_test[i]):\n",
    "            wrong+=1\n",
    "    print(1-(wrong/len(predictions)))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8057c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = test_dataset.take(1)\n",
    "\n",
    "points, labels = list(data)[0]\n",
    "points = points[:8, ...]\n",
    "labels = labels[:8, ...]\n",
    "\n",
    "preds = model.predict(points)\n",
    "preds = tf.math.argmax(preds, -1)\n",
    "\n",
    "points = points.numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "for i in range(8):\n",
    "    ax = fig.add_subplot(2, 4, i + 1, projection=\"3d\")\n",
    "    ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2])\n",
    "    ax.set_title(\n",
    "        \"pred: {:}, label: {:}\".format(\n",
    "            CLASS_MAP[preds[i].numpy()], CLASS_MAP[labels.numpy()[i]]\n",
    "        )\n",
    "    )\n",
    "    print(\"prediction: \" + CLASS_MAP[preds[i].numpy()])\n",
    "    print(\"label: \" + CLASS_MAP[labels.numpy()[i]])\n",
    "    ax.set_axis_off()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34c1bdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98bd90c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(coordinates)\n",
    "o3d.io.write_point_cloud(\"./data.ply\", pcd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "227917de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 209634 points.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(\"data.ply\")\n",
    "print(pcd)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b1958e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10b47ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitin\\anaconda3\\lib\\site-packages\\IPython\\core\\display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    }
   ],
   "source": [
    "mesh2 = trimesh.load(\"data.ply\")\n",
    "mesh2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bedf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bbf42e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 2048 points.\n"
     ]
    }
   ],
   "source": [
    "downpcd = pcd.voxel_down_sample(voxel_size=7.409)\n",
    "print(downpcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb3caedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([downpcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c657bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "from scipy.spatial import distance\n",
    "def closest_node(node, nodes):\n",
    "    closest_index = distance.cdist([node], nodes).argmin()\n",
    "    return nodes[closest_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f9e344ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "down_points = np.asarray(downpcd.points)\n",
    "d = down_points\n",
    "down_points = np.expand_dims(down_points, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b1aec898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[208.35475595, 142.30621604, 206.71854074]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e83ebfcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '' (U+2013) (Temp/ipykernel_15608/2564571265.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Nitin\\AppData\\Local\\Temp/ipykernel_15608/2564571265.py\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    d = (x  x.min())/(x.max()  x.min())\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '' (U+2013)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "d = d/d.sum(axis=-1,keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1a4e260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32362995, 0.33997428, 0.33639577])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_node([0,0,0], d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07285a4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[Open3D Error] (class std::shared_ptr<class open3d::geometry::TriangleMesh> __cdecl open3d::geometry::BallPivoting::Run(const class std::vector<double,class std::allocator<double> > &)) D:\\a\\Open3D\\Open3D\\cpp\\open3d\\geometry\\SurfaceReconstructionBallPivoting.cpp:677: ReconstructBallPivoting requires normals\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15608/401133035.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mavg_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mradius\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mavg_dist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbpa_mesh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo3d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTriangleMesh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_from_point_cloud_ball_pivoting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpcd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo3d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutility\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDoubleVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradius\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdec_mesh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmesh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplify_quadric_decimation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mo3d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_triangle_mesh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"bpa_mesh.ply\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_mesh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [Open3D Error] (class std::shared_ptr<class open3d::geometry::TriangleMesh> __cdecl open3d::geometry::BallPivoting::Run(const class std::vector<double,class std::allocator<double> > &)) D:\\a\\Open3D\\Open3D\\cpp\\open3d\\geometry\\SurfaceReconstructionBallPivoting.cpp:677: ReconstructBallPivoting requires normals\n"
     ]
    }
   ],
   "source": [
    "distances = downpcd.compute_nearest_neighbor_distance()\n",
    "avg_dist = np.mean(distances)\n",
    "radius = 3 * avg_dist\n",
    "bpa_mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(pcd,o3d.utility.DoubleVector([radius, radius * 2]))\n",
    "dec_mesh = mesh.simplify_quadric_decimation(100000)\n",
    "o3d.io.write_triangle_mesh(output_path+\"bpa_mesh.ply\", dec_mesh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6187c9d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15608/3418139737.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdown_points\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "preds = model.predict(down_points)\n",
    "preds = tf.math.argmax(preds, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6daa87ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15608/3965235186.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "print(type(preds[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31dfd57b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CLASS_MAP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15608/2999437717.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCLASS_MAP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'CLASS_MAP' is not defined"
     ]
    }
   ],
   "source": [
    "print(CLASS_MAP[preds[0].numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c392394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "a = random.randint(1000, size=(50000, 2))\n",
    "\n",
    "some_pt = (1, 2)\n",
    "\n",
    "closest_node(some_pt, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d201417",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('C:/Users/Nitin/Downloads/rename.txt') as f:\n",
    "    lines = f.read().splitlines()\n",
    "for i in range(len(lines)):\n",
    "    lines[i] = [float(a) for a in lines[i].split()]\n",
    "positives = []\n",
    "for l in lines:\n",
    "    positives.append(l[0:3])\n",
    "positives = np.array(positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a49040a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = positives/positives.sum(axis=-1,keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d6713cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = o3d.core.Device(\"CPU:0\")\n",
    "dtype = o3d.core.float32\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "613691d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n"
     ]
    }
   ],
   "source": [
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8512a7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.19987987, 0.21828749, 0.58183264],\n",
       "        [0.0703259 , 0.09090909, 0.83876501],\n",
       "        [0.37381129, 0.25531297, 0.37087574],\n",
       "        ...,\n",
       "        [0.41726248, 0.2395466 , 0.34319092],\n",
       "        [0.4091829 , 0.2385146 , 0.3523025 ],\n",
       "        [0.41308028, 0.23571211, 0.35120761]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "839de8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "neg = []\n",
    "for r in (range(len(d))):\n",
    "    close = closest_node(d[r], positives)\n",
    "    if(math.dist(close, d[r])>=0.6):\n",
    "        neg.append(d[r])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c8eeed6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8832356620807347"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(positives[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3923ccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 2.8732 - accuracy: 0.5476\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7402 - accuracy: 0.7367\n",
      "Epoch 3/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.6865\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7556\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7542\n",
      "Epoch 6/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.7360\n",
      "Epoch 7/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9550 - accuracy: 0.6647\n",
      "Epoch 8/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7099 - accuracy: 0.7302\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7615\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.7095 - accuracy: 0.7062\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.9010 - accuracy: 0.6916\n",
      "Epoch 12/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.0758 - accuracy: 0.6618\n",
      "Epoch 13/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.0189 - accuracy: 0.6982\n",
      "Epoch 14/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0968 - accuracy: 0.6938\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7764 - accuracy: 0.7040\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0156 - accuracy: 0.6960\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7600\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7600\n",
      "Epoch 19/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.7149\n",
      "Epoch 20/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.7353\n",
      "Epoch 21/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.7265\n",
      "Epoch 22/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7619 - accuracy: 0.7338\n",
      "Epoch 23/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7145 - accuracy: 0.7113\n",
      "Epoch 24/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7465 - accuracy: 0.7178\n",
      "Epoch 25/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9618 - accuracy: 0.6807\n",
      "Epoch 26/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7695\n",
      "Epoch 27/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.7462\n",
      "Epoch 28/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6691 - accuracy: 0.7324\n",
      "Epoch 29/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8489 - accuracy: 0.6880\n",
      "Epoch 30/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0689 - accuracy: 0.6705\n",
      "Epoch 31/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3101 - accuracy: 0.6633\n",
      "Epoch 32/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7160 - accuracy: 0.7680\n",
      "Epoch 33/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7796 - accuracy: 0.7215\n",
      "Epoch 34/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.7425\n",
      "Epoch 35/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0441 - accuracy: 0.6909\n",
      "Epoch 36/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.7331\n",
      "Epoch 37/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.7389\n",
      "Epoch 38/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.7375\n",
      "Epoch 39/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9995 - accuracy: 0.7011\n",
      "Epoch 40/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8112 - accuracy: 0.7113\n",
      "Epoch 41/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.7222\n",
      "Epoch 42/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7020 - accuracy: 0.7062\n",
      "Epoch 43/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.7367\n",
      "Epoch 44/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7542\n",
      "Epoch 45/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3742 - accuracy: 0.6356\n",
      "Epoch 46/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.7731\n",
      "Epoch 47/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7651\n",
      "Epoch 48/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0099 - accuracy: 0.6705\n",
      "Epoch 49/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.7542\n",
      "Epoch 50/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.7542\n",
      "Epoch 51/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7435 - accuracy: 0.7135\n",
      "Epoch 52/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.7258\n",
      "Epoch 53/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7776 - accuracy: 0.7127\n",
      "Epoch 54/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0190 - accuracy: 0.6858\n",
      "Epoch 55/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7110 - accuracy: 0.7258\n",
      "Epoch 56/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0277 - accuracy: 0.6771\n",
      "Epoch 57/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.7636\n",
      "Epoch 58/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.7273\n",
      "Epoch 59/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7165 - accuracy: 0.7236\n",
      "Epoch 60/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7988 - accuracy: 0.7011\n",
      "Epoch 61/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6648 - accuracy: 0.7316\n",
      "Epoch 62/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.3100 - accuracy: 0.6575\n",
      "Epoch 63/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.9423 - accuracy: 0.7200\n",
      "Epoch 64/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.7498\n",
      "Epoch 65/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.7251\n",
      "Epoch 66/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.7244\n",
      "Epoch 67/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8917 - accuracy: 0.7091\n",
      "Epoch 68/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.7018\n",
      "Epoch 69/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4423 - accuracy: 0.6516\n",
      "Epoch 70/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.9309 - accuracy: 0.7549\n",
      "Epoch 71/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7465 - accuracy: 0.7156\n",
      "Epoch 72/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9601 - accuracy: 0.6945\n",
      "Epoch 73/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.7578\n",
      "Epoch 74/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8594 - accuracy: 0.6938\n",
      "Epoch 75/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.7644\n",
      "Epoch 76/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.7215\n",
      "Epoch 77/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7786 - accuracy: 0.7105\n",
      "Epoch 78/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.7360\n",
      "Epoch 79/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7232 - accuracy: 0.7295\n",
      "Epoch 80/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0701 - accuracy: 0.6676\n",
      "Epoch 81/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.7925 - accuracy: 0.7316\n",
      "Epoch 82/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.7404\n",
      "Epoch 83/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.7345\n",
      "Epoch 84/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.7425\n",
      "Epoch 85/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8349 - accuracy: 0.6822\n",
      "Epoch 86/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.7571\n",
      "Epoch 87/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.0103 - accuracy: 0.6720\n",
      "Epoch 88/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9985 - accuracy: 0.7156\n",
      "Epoch 89/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.7329 - accuracy: 0.7331\n",
      "Epoch 90/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7992 - accuracy: 0.6742\n",
      "Epoch 91/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9472 - accuracy: 0.7047\n",
      "Epoch 92/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7335 - accuracy: 0.7229\n",
      "Epoch 93/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5929 - accuracy: 0.7578\n",
      "Epoch 94/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6431 - accuracy: 0.7455\n",
      "Epoch 95/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7469\n",
      "Epoch 96/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.8881 - accuracy: 0.6785\n",
      "Epoch 97/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2088 - accuracy: 0.6625\n",
      "Epoch 98/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8558 - accuracy: 0.7178\n",
      "Epoch 99/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.7564\n",
      "Epoch 100/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8178 - accuracy: 0.7105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x221fff15e80>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(1, 3)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model2.fit(points_train, labels_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c4936bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.78854482e-02, 9.72114563e-01],\n",
       "       [6.98661268e-01, 3.01338762e-01],\n",
       "       [1.78043563e-02, 9.82195675e-01],\n",
       "       [6.69183493e-01, 3.30816507e-01],\n",
       "       [7.20675945e-01, 2.79324085e-01],\n",
       "       [9.77541268e-01, 2.24587284e-02],\n",
       "       [8.67503703e-01, 1.32496357e-01],\n",
       "       [7.79177129e-01, 2.20822841e-01],\n",
       "       [9.98886287e-01, 1.11371605e-03],\n",
       "       [9.74897265e-01, 2.51027383e-02],\n",
       "       [3.07876796e-01, 6.92123234e-01],\n",
       "       [9.69945669e-01, 3.00543793e-02],\n",
       "       [1.45456782e-02, 9.85454321e-01],\n",
       "       [9.09774423e-01, 9.02255103e-02],\n",
       "       [2.22569108e-01, 7.77430952e-01],\n",
       "       [2.50323147e-01, 7.49676824e-01],\n",
       "       [2.77187228e-02, 9.72281337e-01],\n",
       "       [8.51966664e-02, 9.14803386e-01],\n",
       "       [2.90238089e-03, 9.97097611e-01],\n",
       "       [2.84007490e-02, 9.71599221e-01],\n",
       "       [8.23845446e-01, 1.76154479e-01],\n",
       "       [9.02413070e-01, 9.75869074e-02],\n",
       "       [2.42327247e-03, 9.97576773e-01],\n",
       "       [9.56881523e-01, 4.31184918e-02],\n",
       "       [2.52386020e-03, 9.97476161e-01],\n",
       "       [8.60239208e-01, 1.39760837e-01],\n",
       "       [8.00247908e-01, 1.99752182e-01],\n",
       "       [1.75187513e-01, 8.24812531e-01],\n",
       "       [5.00651821e-02, 9.49934781e-01],\n",
       "       [9.88171875e-01, 1.18280975e-02],\n",
       "       [9.47951615e-01, 5.20483628e-02],\n",
       "       [3.48412283e-02, 9.65158761e-01],\n",
       "       [8.32849264e-01, 1.67150676e-01],\n",
       "       [1.93497743e-02, 9.80650306e-01],\n",
       "       [1.24460541e-01, 8.75539422e-01],\n",
       "       [9.77902293e-01, 2.20977031e-02],\n",
       "       [9.98929322e-01, 1.07060617e-03],\n",
       "       [9.78325725e-01, 2.16743033e-02],\n",
       "       [4.73597385e-02, 9.52640235e-01],\n",
       "       [9.15361106e-01, 8.46389383e-02],\n",
       "       [1.20102197e-01, 8.79897833e-01],\n",
       "       [8.51761222e-01, 1.48238808e-01],\n",
       "       [5.01497746e-01, 4.98502254e-01],\n",
       "       [7.60277733e-02, 9.23972249e-01],\n",
       "       [8.82053733e-01, 1.17946252e-01],\n",
       "       [9.94928122e-01, 5.07184910e-03],\n",
       "       [7.16877580e-01, 2.83122420e-01],\n",
       "       [9.99009132e-01, 9.90847708e-04],\n",
       "       [1.57438405e-02, 9.84256208e-01],\n",
       "       [3.17945957e-01, 6.82054043e-01],\n",
       "       [1.77487871e-03, 9.98225152e-01],\n",
       "       [9.25835431e-01, 7.41645470e-02],\n",
       "       [9.88514006e-01, 1.14859520e-02],\n",
       "       [7.26991177e-01, 2.73008853e-01],\n",
       "       [9.89258826e-01, 1.07412217e-02],\n",
       "       [5.42775750e-01, 4.57224309e-01],\n",
       "       [4.24336176e-03, 9.95756567e-01],\n",
       "       [2.46092871e-01, 7.53907144e-01],\n",
       "       [9.60090458e-01, 3.99095342e-02],\n",
       "       [9.14702058e-01, 8.52979496e-02],\n",
       "       [9.85090494e-01, 1.49094723e-02],\n",
       "       [7.13970184e-01, 2.86029756e-01],\n",
       "       [7.18989819e-02, 9.28101063e-01],\n",
       "       [9.85291958e-01, 1.47080347e-02],\n",
       "       [8.52099001e-01, 1.47900984e-01],\n",
       "       [9.89405334e-01, 1.05946334e-02],\n",
       "       [9.93064940e-01, 6.93508424e-03],\n",
       "       [2.35953066e-03, 9.97640491e-01],\n",
       "       [7.68404424e-01, 2.31595546e-01],\n",
       "       [3.15836295e-02, 9.68416393e-01],\n",
       "       [9.90046084e-01, 9.95394122e-03],\n",
       "       [7.21889496e-01, 2.78110504e-01],\n",
       "       [9.34937179e-01, 6.50627762e-02],\n",
       "       [8.74344632e-03, 9.91256595e-01],\n",
       "       [9.89597797e-01, 1.04021868e-02],\n",
       "       [7.76582599e-01, 2.23417446e-01],\n",
       "       [7.05752552e-01, 2.94247448e-01],\n",
       "       [9.95950222e-01, 4.04971559e-03],\n",
       "       [1.23975627e-01, 8.76024365e-01],\n",
       "       [7.26353168e-01, 2.73646772e-01],\n",
       "       [3.04771904e-02, 9.69522834e-01],\n",
       "       [2.64084116e-02, 9.73591566e-01],\n",
       "       [8.33866417e-01, 1.66133538e-01],\n",
       "       [2.40256160e-01, 7.59743810e-01],\n",
       "       [8.63618433e-01, 1.36381552e-01],\n",
       "       [2.93004420e-03, 9.97069955e-01],\n",
       "       [5.81611544e-02, 9.41838801e-01],\n",
       "       [1.24621093e-01, 8.75378907e-01],\n",
       "       [5.03145635e-01, 4.96854335e-01],\n",
       "       [9.39020395e-01, 6.09796606e-02],\n",
       "       [9.88505840e-01, 1.14941411e-02],\n",
       "       [7.17175961e-01, 2.82824069e-01],\n",
       "       [1.09323524e-01, 8.90676439e-01],\n",
       "       [6.05714554e-03, 9.93942797e-01],\n",
       "       [6.78544998e-01, 3.21455002e-01],\n",
       "       [2.89479584e-01, 7.10520446e-01],\n",
       "       [9.82685804e-01, 1.73141584e-02],\n",
       "       [3.12728919e-02, 9.68727112e-01],\n",
       "       [3.45325023e-02, 9.65467453e-01],\n",
       "       [1.82538196e-01, 8.17461789e-01],\n",
       "       [7.46494353e-01, 2.53505677e-01],\n",
       "       [9.89411652e-01, 1.05882976e-02],\n",
       "       [2.17597652e-03, 9.97824073e-01],\n",
       "       [8.24525416e-01, 1.75474599e-01],\n",
       "       [9.69146430e-01, 3.08535900e-02],\n",
       "       [6.12831593e-01, 3.87168407e-01],\n",
       "       [7.74651349e-01, 2.25348696e-01],\n",
       "       [2.75688857e-01, 7.24311113e-01],\n",
       "       [5.98237932e-01, 4.01762068e-01],\n",
       "       [9.37301636e-01, 6.26983568e-02],\n",
       "       [3.13089718e-03, 9.96869147e-01],\n",
       "       [8.13132942e-01, 1.86867058e-01],\n",
       "       [9.85111058e-01, 1.48889534e-02],\n",
       "       [3.46479611e-03, 9.96535182e-01],\n",
       "       [9.99041736e-01, 9.58269462e-04],\n",
       "       [2.06462458e-01, 7.93537498e-01],\n",
       "       [5.12690187e-01, 4.87309784e-01],\n",
       "       [9.93285835e-01, 6.71413634e-03],\n",
       "       [3.22568156e-02, 9.67743218e-01],\n",
       "       [9.84163582e-01, 1.58363804e-02],\n",
       "       [8.02630484e-01, 1.97369501e-01],\n",
       "       [7.54042268e-01, 2.45957702e-01],\n",
       "       [7.84744680e-01, 2.15255380e-01],\n",
       "       [1.62323508e-02, 9.83767629e-01],\n",
       "       [9.75133657e-01, 2.48663332e-02],\n",
       "       [9.90031004e-01, 9.96895134e-03],\n",
       "       [7.13561833e-01, 2.86438167e-01],\n",
       "       [9.97887313e-01, 2.11273786e-03],\n",
       "       [8.19910765e-01, 1.80089191e-01],\n",
       "       [7.28317499e-01, 2.71682471e-01],\n",
       "       [9.94848907e-01, 5.15111256e-03],\n",
       "       [9.32061851e-01, 6.79381713e-02],\n",
       "       [3.04159801e-03, 9.96958375e-01],\n",
       "       [9.89032209e-01, 1.09677669e-02],\n",
       "       [8.29557836e-01, 1.70442194e-01],\n",
       "       [9.99009132e-01, 9.90847708e-04],\n",
       "       [4.95804936e-01, 5.04195154e-01],\n",
       "       [9.06257570e-01, 9.37424824e-02],\n",
       "       [6.78063869e-01, 3.21936131e-01],\n",
       "       [3.56914033e-03, 9.96430874e-01],\n",
       "       [9.56525188e-03, 9.90434766e-01],\n",
       "       [9.86665249e-01, 1.33348322e-02],\n",
       "       [4.79561299e-01, 5.20438731e-01],\n",
       "       [9.89253461e-01, 1.07466141e-02],\n",
       "       [2.12545437e-03, 9.97874498e-01],\n",
       "       [9.90488887e-01, 9.51112248e-03],\n",
       "       [1.49359971e-01, 8.50640059e-01],\n",
       "       [2.52366289e-02, 9.74763393e-01],\n",
       "       [9.58061218e-01, 4.19388004e-02],\n",
       "       [1.66257042e-02, 9.83374357e-01],\n",
       "       [7.33652771e-01, 2.66347200e-01],\n",
       "       [7.62254059e-01, 2.37745970e-01],\n",
       "       [6.80681348e-01, 3.19318682e-01],\n",
       "       [9.72541153e-01, 2.74588857e-02],\n",
       "       [2.59466912e-03, 9.97405350e-01],\n",
       "       [9.90458488e-01, 9.54146497e-03],\n",
       "       [4.05800752e-02, 9.59419847e-01],\n",
       "       [9.90691245e-01, 9.30876844e-03],\n",
       "       [3.81792039e-01, 6.18207991e-01],\n",
       "       [2.61649005e-02, 9.73835111e-01],\n",
       "       [8.66505802e-01, 1.33494183e-01],\n",
       "       [2.14225501e-01, 7.85774529e-01],\n",
       "       [9.63810563e-01, 3.61895077e-02],\n",
       "       [8.19118321e-01, 1.80881664e-01],\n",
       "       [8.32554340e-01, 1.67445615e-01],\n",
       "       [9.92084622e-01, 7.91540649e-03],\n",
       "       [2.85729896e-02, 9.71426964e-01],\n",
       "       [9.95098531e-01, 4.90145991e-03],\n",
       "       [9.88119543e-01, 1.18804453e-02],\n",
       "       [9.79605436e-01, 2.03945637e-02],\n",
       "       [8.37447107e-01, 1.62552878e-01],\n",
       "       [2.82104220e-02, 9.71789539e-01],\n",
       "       [4.40548241e-01, 5.59451759e-01],\n",
       "       [7.96549737e-01, 2.03450218e-01],\n",
       "       [9.40812111e-01, 5.91879450e-02],\n",
       "       [9.88203108e-01, 1.17969057e-02],\n",
       "       [9.21462476e-02, 9.07853782e-01],\n",
       "       [8.38590205e-01, 1.61409810e-01],\n",
       "       [7.86429703e-01, 2.13570297e-01],\n",
       "       [7.10715413e-01, 2.89284647e-01],\n",
       "       [2.07048771e-03, 9.97929454e-01],\n",
       "       [2.84765344e-02, 9.71523523e-01],\n",
       "       [5.33470511e-02, 9.46652949e-01],\n",
       "       [5.85229555e-03, 9.94147658e-01],\n",
       "       [1.14011988e-01, 8.85987997e-01],\n",
       "       [1.23768635e-01, 8.76231372e-01],\n",
       "       [9.92081046e-01, 7.91895576e-03],\n",
       "       [6.15219809e-02, 9.38477993e-01],\n",
       "       [4.23924476e-02, 9.57607567e-01],\n",
       "       [9.89840567e-01, 1.01593519e-02],\n",
       "       [7.23212123e-01, 2.76787877e-01],\n",
       "       [1.93600543e-02, 9.80639935e-01],\n",
       "       [9.90872800e-01, 9.12720710e-03],\n",
       "       [1.15358680e-01, 8.84641349e-01],\n",
       "       [7.35929787e-01, 2.64070272e-01],\n",
       "       [3.17347934e-03, 9.96826530e-01],\n",
       "       [9.80419099e-01, 1.95809007e-02],\n",
       "       [9.90046084e-01, 9.95394122e-03],\n",
       "       [9.62184548e-01, 3.78153846e-02],\n",
       "       [8.37973237e-01, 1.62026748e-01],\n",
       "       [2.35273689e-02, 9.76472676e-01],\n",
       "       [9.98756289e-01, 1.24365336e-03],\n",
       "       [9.90458488e-01, 9.54146497e-03],\n",
       "       [8.92306566e-01, 1.07693449e-01],\n",
       "       [9.74729180e-01, 2.52708588e-02],\n",
       "       [7.18046367e-01, 2.81953633e-01],\n",
       "       [4.00768667e-02, 9.59923148e-01],\n",
       "       [9.76237416e-01, 2.37625893e-02],\n",
       "       [8.21517825e-01, 1.78482205e-01],\n",
       "       [3.31490077e-02, 9.66850996e-01],\n",
       "       [6.98223040e-02, 9.30177748e-01],\n",
       "       [1.53829008e-01, 8.46170962e-01],\n",
       "       [7.67156005e-01, 2.32843935e-01],\n",
       "       [1.17471144e-02, 9.88252938e-01],\n",
       "       [7.04360366e-01, 2.95639664e-01],\n",
       "       [9.85146821e-01, 1.48532148e-02],\n",
       "       [2.70616077e-02, 9.72938418e-01],\n",
       "       [7.08589613e-01, 2.91410357e-01],\n",
       "       [3.07117812e-02, 9.69288230e-01],\n",
       "       [8.64247829e-02, 9.13575292e-01],\n",
       "       [2.90942704e-03, 9.97090578e-01],\n",
       "       [8.79857838e-01, 1.20142102e-01],\n",
       "       [8.22541893e-01, 1.77458137e-01],\n",
       "       [9.25152361e-01, 7.48476684e-02],\n",
       "       [6.66948199e-01, 3.33051860e-01],\n",
       "       [9.91394222e-02, 9.00860548e-01],\n",
       "       [8.79473984e-02, 9.12052572e-01],\n",
       "       [1.34425327e-01, 8.65574658e-01],\n",
       "       [4.57666457e-01, 5.42333603e-01],\n",
       "       [9.49820653e-02, 9.05017972e-01],\n",
       "       [9.95607197e-01, 4.39274264e-03],\n",
       "       [8.50574553e-01, 1.49425417e-01],\n",
       "       [4.17655632e-02, 9.58234489e-01],\n",
       "       [9.82007802e-01, 1.79922767e-02],\n",
       "       [6.37530744e-01, 3.62469226e-01],\n",
       "       [9.13898647e-01, 8.61013904e-02],\n",
       "       [3.14491428e-02, 9.68550801e-01],\n",
       "       [9.95939374e-01, 4.06061625e-03],\n",
       "       [8.56445804e-02, 9.14355397e-01],\n",
       "       [6.95738420e-02, 9.30426180e-01],\n",
       "       [9.02413070e-01, 9.75869074e-02],\n",
       "       [8.80532742e-01, 1.19467326e-01],\n",
       "       [7.31537223e-01, 2.68462807e-01],\n",
       "       [6.86805129e-01, 3.13194901e-01],\n",
       "       [2.27360893e-02, 9.77263927e-01],\n",
       "       [2.43169698e-03, 9.97568309e-01],\n",
       "       [1.38995513e-01, 8.61004472e-01],\n",
       "       [2.68924329e-02, 9.73107636e-01],\n",
       "       [9.77902293e-01, 2.20977031e-02],\n",
       "       [9.47951615e-01, 5.20483628e-02],\n",
       "       [9.92187500e-01, 7.81244272e-03],\n",
       "       [2.14796603e-01, 7.85203457e-01],\n",
       "       [8.83890629e-01, 1.16109408e-01],\n",
       "       [2.47240695e-03, 9.97527659e-01],\n",
       "       [5.25551975e-01, 4.74448085e-01],\n",
       "       [8.14552903e-01, 1.85447067e-01],\n",
       "       [3.05797726e-01, 6.94202244e-01],\n",
       "       [1.48098054e-03, 9.98519003e-01],\n",
       "       [5.99581778e-01, 4.00418222e-01],\n",
       "       [7.14758754e-01, 2.85241276e-01],\n",
       "       [1.92237571e-02, 9.80776310e-01],\n",
       "       [8.28660309e-01, 1.71339676e-01],\n",
       "       [2.25686678e-03, 9.97743130e-01],\n",
       "       [9.84072506e-01, 1.59274545e-02],\n",
       "       [8.36066604e-01, 1.63933456e-01],\n",
       "       [2.24704966e-02, 9.77529526e-01],\n",
       "       [9.73625004e-01, 2.63749361e-02],\n",
       "       [3.72131984e-03, 9.96278703e-01],\n",
       "       [9.41074491e-01, 5.89255132e-02],\n",
       "       [3.23692933e-02, 9.67630684e-01],\n",
       "       [5.17425656e-01, 4.82574403e-01],\n",
       "       [9.92187500e-01, 7.81244272e-03],\n",
       "       [9.92070377e-01, 7.92955607e-03],\n",
       "       [2.10466478e-02, 9.78953302e-01],\n",
       "       [8.61905038e-01, 1.38094977e-01],\n",
       "       [9.07974184e-01, 9.20258537e-02],\n",
       "       [9.94815528e-01, 5.18440269e-03],\n",
       "       [9.89411652e-01, 1.05882976e-02],\n",
       "       [3.77985418e-01, 6.22014582e-01],\n",
       "       [8.99901688e-01, 1.00098319e-01],\n",
       "       [7.83947766e-01, 2.16052234e-01],\n",
       "       [1.00636505e-01, 8.99363518e-01],\n",
       "       [9.83991444e-01, 1.60085838e-02],\n",
       "       [3.09726689e-02, 9.69027340e-01],\n",
       "       [9.98634875e-01, 1.36511307e-03],\n",
       "       [2.08362609e-01, 7.91637421e-01],\n",
       "       [9.62155521e-01, 3.78444791e-02],\n",
       "       [1.91904756e-03, 9.98080969e-01],\n",
       "       [8.42620492e-01, 1.57379523e-01],\n",
       "       [9.15111840e-01, 8.48881081e-02],\n",
       "       [9.97198939e-01, 2.80110305e-03],\n",
       "       [8.73613730e-02, 9.12638605e-01],\n",
       "       [9.49196637e-01, 5.08033223e-02],\n",
       "       [9.87997174e-01, 1.20028025e-02],\n",
       "       [9.15966108e-02, 9.08403456e-01],\n",
       "       [9.98960137e-01, 1.03981106e-03],\n",
       "       [9.74526465e-01, 2.54734792e-02],\n",
       "       [9.74982917e-01, 2.50170864e-02],\n",
       "       [3.33429105e-03, 9.96665657e-01],\n",
       "       [8.09413970e-01, 1.90585986e-01],\n",
       "       [8.10705543e-01, 1.89294428e-01],\n",
       "       [7.77385056e-01, 2.22614974e-01],\n",
       "       [6.05466329e-02, 9.39453304e-01],\n",
       "       [7.82363236e-01, 2.17636824e-01],\n",
       "       [9.50279355e-01, 4.97206114e-02],\n",
       "       [9.58061218e-01, 4.19388004e-02],\n",
       "       [1.65803113e-03, 9.98341918e-01],\n",
       "       [5.29132724e-01, 4.70867306e-01],\n",
       "       [7.34081507e-01, 2.65918434e-01],\n",
       "       [1.98838720e-03, 9.98011589e-01],\n",
       "       [4.01523709e-03, 9.95984793e-01],\n",
       "       [7.10283816e-01, 2.89716214e-01],\n",
       "       [1.05822529e-03, 9.98941839e-01],\n",
       "       [8.90996754e-01, 1.09003194e-01],\n",
       "       [4.36895102e-01, 5.63104868e-01],\n",
       "       [9.96305346e-01, 3.69460764e-03],\n",
       "       [9.07134831e-01, 9.28651765e-02],\n",
       "       [7.02369750e-01, 2.97630191e-01],\n",
       "       [7.63112307e-02, 9.23688769e-01],\n",
       "       [3.63293409e-01, 6.36706591e-01],\n",
       "       [6.93704784e-01, 3.06295156e-01],\n",
       "       [1.59051679e-02, 9.84094799e-01],\n",
       "       [7.11106956e-01, 2.88893014e-01],\n",
       "       [8.22597563e-01, 1.77402467e-01],\n",
       "       [8.62629890e-01, 1.37370095e-01],\n",
       "       [7.23483086e-01, 2.76516885e-01],\n",
       "       [9.76653516e-01, 2.33465079e-02],\n",
       "       [3.19343479e-03, 9.96806622e-01],\n",
       "       [9.90170300e-01, 9.82973631e-03],\n",
       "       [7.85338104e-01, 2.14661822e-01],\n",
       "       [9.93859351e-01, 6.14066748e-03],\n",
       "       [9.99075294e-01, 9.24693886e-04],\n",
       "       [9.59959745e-01, 4.00402658e-02],\n",
       "       [1.50757506e-01, 8.49242449e-01],\n",
       "       [5.22405863e-01, 4.77594137e-01],\n",
       "       [7.36208379e-01, 2.63791591e-01],\n",
       "       [7.30654120e-01, 2.69345880e-01],\n",
       "       [6.51189405e-03, 9.93488073e-01],\n",
       "       [3.45272943e-02, 9.65472698e-01],\n",
       "       [8.74402285e-01, 1.25597730e-01],\n",
       "       [9.88514006e-01, 1.14859520e-02],\n",
       "       [4.58656549e-01, 5.41343510e-01],\n",
       "       [1.19182698e-01, 8.80817294e-01],\n",
       "       [1.77720166e-03, 9.98222768e-01]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model2.predict([points_test])\n",
    "preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
